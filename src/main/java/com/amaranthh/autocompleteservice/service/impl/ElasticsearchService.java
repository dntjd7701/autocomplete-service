package com.amaranthh.autocompleteservice.service.impl;

import co.elastic.clients.elasticsearch.ElasticsearchClient;
import co.elastic.clients.elasticsearch.core.*;
import co.elastic.clients.elasticsearch.core.bulk.BulkOperation;
import co.elastic.clients.elasticsearch.indices.CreateIndexRequest;
import co.elastic.clients.elasticsearch.indices.CreateIndexResponse;
import com.amaranthh.autocompleteservice.model.AutoComplete;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.core.io.ClassPathResource;
import org.springframework.stereotype.Service;
import org.springframework.util.StreamUtils;

import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

@Service
@RequiredArgsConstructor
@Slf4j
public class ElasticsearchService {

    private final ElasticsearchClient elasticsearchClient;

    private static final String INDEX_NAME = "autocomplete-index";

    // ì¸ë±ìŠ¤ ìƒì„±
    public void createAutocompleteIndex()  {
        try {
            boolean exists = elasticsearchClient.indices().exists(e -> e.index(INDEX_NAME)).value();

            if (exists) {
                System.out.println("Index already exists.");
                return;
            }

            // JSON íŒŒì¼ ì½ì–´ì˜¤ê¸°
            ClassPathResource resource = new ClassPathResource(INDEX_NAME + ".json");
            String json = StreamUtils.copyToString(resource.getInputStream(), StandardCharsets.UTF_8);

            // Index ìƒì„±
            CreateIndexRequest createIndexRequest = new CreateIndexRequest.Builder()
                    .index("autocomplete-index")
                    .withJson(new ByteArrayInputStream(json.getBytes(StandardCharsets.UTF_8)))
                    .build();

            CreateIndexResponse response = elasticsearchClient.indices().create(createIndexRequest);

            System.out.println("Index created: " + response.acknowledged());
        } catch (IOException e) {
            log.error("âŒ Failed to create index", e);
            throw new RuntimeException("Failed to create index", e); // RuntimeException ìœ¼ë¡œ ê°ì‹¸ì„œ ìƒìœ„ë¡œ ë˜ì§
        }
    }

    // ë¬¸ì„œ ë“±ë¡ (Indexing) / ìˆ˜ì •(delete + insert)
    public void indexDocument(String id, AutoComplete doc) {
        try {
            IndexResponse response = elasticsearchClient.index(i -> i
                    .index(INDEX_NAME)
                    .id(id)
                    .document(doc)
            );


        log.info("Document indexed with version: {}", response.version());
        } catch (IOException e) {
            log.error("âŒ Failed to indexing", e);
            throw new RuntimeException(e);
        }
    }


    public List<AutoComplete> search(Map<String, String> param) {

        try {
            String _keyword = param.get("keyword");
            SearchResponse<AutoComplete> response = elasticsearchClient.search(s -> s
                                .index(INDEX_NAME)
                                .size(10)
                                .query(q -> q
                                        .bool(b -> b
                                                // ğŸ”¶ filter â†’ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•˜ëŠ” í•„í„° ì¡°ê±´ (score ì— ì˜í–¥ X, ë¹ ë¦„)
                                                .filter(f -> f.term(t -> t.field("coCd").value(param.get("coCd"))))   // coCd ê°€ ì •í™•íˆ param.get("coCd") ì™€ ì¼ì¹˜
                                                .filter(f -> f.term(t -> t.field("divCd").value(param.get("divCd")))) // divCd ê°€ ì •í™•íˆ param.get("divCd") ì™€ ì¼ì¹˜
                                                .filter(f -> f.term(t -> t.field("category").value(param.get("category")))) // category ê°€ ì •í™•íˆ param.get("category") ì™€ ì¼ì¹˜

                                                // ğŸ”¶ should â†’ OR ì¡°ê±´, relevance score ì— ì˜í–¥ ì¤Œ (match ë˜ëŠ” matchPhrasePrefix ë¡œ ì‚¬ìš©)
                                                .should(s1 -> s1.matchPhrasePrefix(mp -> mp
                                                        .field("code")           // code í•„ë“œì—ì„œ
                                                        .query(_keyword)))       // _keywordë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥(prefix) ë§¤ì¹­

                                                .should(s2 -> s2.matchPhrasePrefix(mp -> mp
                                                        .field("name.ko")        // name.ko í•„ë“œì—ì„œ
                                                        .query(_keyword)         // _keywordë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥(prefix) ë§¤ì¹­
                                                        .boost(2.0f)))           // ì´ ì¡°ê±´ì— ê°€ì¤‘ì¹˜(ì¤‘ìš”ë„) 2ë°° ë¶€ì—¬ â†’ ìš°ì„ ìˆœìœ„ ë†’ìŒ

                                                .should(s3 -> s3.matchPhrasePrefix(mp -> mp
                                                        .field("name.en")        // name.en í•„ë“œì—ì„œ
                                                        .query(_keyword)))       // _keywordë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥(prefix) ë§¤ì¹­
                                        )
                                ),
                        AutoComplete.class
                );

//            SearchResponse<Map> response = elasticsearchClient.search(s -> s
//                            .index(INDEX_NAME)
//                            .size(10)
//                            .query(q -> q
//                                    .bool(b -> b
//                                            // ğŸ”¶ filter â†’ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•˜ëŠ” í•„í„° ì¡°ê±´ (score ì— ì˜í–¥ X, ë¹ ë¦„)
//                                            .filter(f -> f.term(t -> t.field("coCd").value(param.get("coCd"))))   // coCd ê°€ ì •í™•íˆ param.get("coCd") ì™€ ì¼ì¹˜
//                                            .filter(f -> f.term(t -> t.field("divCd").value(param.get("divCd")))) // divCd ê°€ ì •í™•íˆ param.get("divCd") ì™€ ì¼ì¹˜
//                                            .filter(f -> f.term(t -> t.field("category").value(param.get("category")))) // category ê°€ ì •í™•íˆ param.get("category") ì™€ ì¼ì¹˜
//
//                                            // ğŸ”¶ should â†’ OR ì¡°ê±´, relevance score ì— ì˜í–¥ ì¤Œ (match ë˜ëŠ” matchPhrasePrefix ë¡œ ì‚¬ìš©)
//                                            .should(s1 -> s1.matchPhrasePrefix(mp -> mp
//                                                    .field("code")           // code í•„ë“œì—ì„œ
//                                                    .query(_keyword)))       // _keywordë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥(prefix) ë§¤ì¹­
//
//                                            .should(s2 -> s2.matchPhrasePrefix(mp -> mp
//                                                    .field("name.ko")        // name.ko í•„ë“œì—ì„œ
//                                                    .query(_keyword)         // _keywordë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥(prefix) ë§¤ì¹­
//                                                    .boost(2.0f)))           // ì´ ì¡°ê±´ì— ê°€ì¤‘ì¹˜(ì¤‘ìš”ë„) 2ë°° ë¶€ì—¬ â†’ ìš°ì„ ìˆœìœ„ ë†’ìŒ
//
//                                            .should(s3 -> s3.matchPhrasePrefix(mp -> mp
//                                                    .field("name.en")        // name.en í•„ë“œì—ì„œ
//                                                    .query(_keyword)))       // _keywordë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥(prefix) ë§¤ì¹­
//                                    )
//                            ),
//                    Map.class
//            );

//            response.hits().hits().forEach(hit -> {
//                System.out.println("Found document: " + hit.source());
//            });
            return response.hits().hits().stream()
                    .map(hit -> {
                        AutoComplete doc = hit.source();
                        doc.setId(hit.id());  // _id ë³„ë„ ì„¤ì • (ì›í•œë‹¤ë©´)
                        return doc;
                    })
                    .collect(Collectors.toList());
        } catch (IOException e) {
            log.error("âŒ Failed to search", e);
            throw new RuntimeException(e);
        }

    };

    public void buildIndex(List<AutoComplete> docs) {
        int batchSize = 1000;
        int totalSize = docs.size();
        int totalBatches = (int) Math.ceil((double) totalSize / batchSize);
        long start = System.currentTimeMillis();

        log.info("ğŸš€ ì¸ë±ì‹± ì‹œì‘ - ì´ {}ê±´, ë°°ì¹˜ë‹¹ {}ê±´ (ì´ {}ë°°ì¹˜)", totalSize, batchSize, totalBatches);

        for (int i = 0; i < totalSize; i += batchSize) {
            int currentBatch = (i / batchSize) + 1;

            List<BulkOperation> operations = docs.subList(i, Math.min(i + batchSize, totalSize))
                    .stream()
                    .map(doc -> BulkOperation.of(b -> b
                            .index(idx -> idx
                                    .index(INDEX_NAME)
                                    .id(doc.getId())
                                    .document(doc)
                            )
                    ))
                    .collect(Collectors.toList());

            BulkRequest bulkRequest = new BulkRequest.Builder()
                    .index(INDEX_NAME)
                    .operations(operations)
                    .build();

            BulkResponse bulkResponse = null;

            try {
                bulkResponse = elasticsearchClient.bulk(bulkRequest);
            } catch (IOException e) {
                log.error("âŒ Failed to bulk", e);
                throw new RuntimeException(e);
            }

            log.info("âœ… [{} / {}] ë°°ì¹˜ ì™„ë£Œ (ì§„í–‰ë¥ : {}%) - ëˆ„ì  ì²˜ë¦¬ ë¬¸ì„œ: {}ê±´ (errors={})",
                    currentBatch,
                    totalBatches,
                    (currentBatch * 100) / totalBatches,
                    i + operations.size(),
                    bulkResponse.errors()
            );
        }

        long duration = System.currentTimeMillis() - start;
        log.info("ğŸ‰ ì¸ë±ì‹± ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {}ms", duration);
    }

    public void delete(String id){
        try {
            DeleteResponse response = elasticsearchClient.delete(d -> d
                    .index(INDEX_NAME)
                    .id(id)
            );

            log.info("Deleted document id={}, result={}", id, response.result().name());
        } catch (IOException e) {
            log.error("âŒ Failed to delete", e);
            throw new RuntimeException(e);
        }
      }

}
