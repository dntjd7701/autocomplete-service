package com.amaranthh.autocompleteservice.service.impl;

import co.elastic.clients.elasticsearch.ElasticsearchClient;
import co.elastic.clients.elasticsearch.core.*;
import co.elastic.clients.elasticsearch.core.bulk.BulkOperation;
import co.elastic.clients.elasticsearch.indices.CreateIndexRequest;
import co.elastic.clients.elasticsearch.indices.CreateIndexResponse;
import com.amaranthh.autocompleteservice.model.AutoComplete;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.core.io.ClassPathResource;
import org.springframework.stereotype.Service;
import org.springframework.util.StreamUtils;

import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

@Service
@RequiredArgsConstructor
@Slf4j
public class ElasticsearchService {

    private final ElasticsearchClient elasticsearchClient;

    private static final String INDEX_NAME = "autocomplete-index";

    // Ïù∏Îç±Ïä§ ÏÉùÏÑ±
    public void createAutocompleteIndex()  {
        try {
            boolean exists = elasticsearchClient.indices().exists(e -> e.index(INDEX_NAME)).value();

            if (exists) {
                System.out.println("Index already exists.");
                return;
            }

            // JSON ÌååÏùº ÏùΩÏñ¥Ïò§Í∏∞
            ClassPathResource resource = new ClassPathResource(INDEX_NAME + ".json");
            String json = StreamUtils.copyToString(resource.getInputStream(), StandardCharsets.UTF_8);

            // Index ÏÉùÏÑ±
            CreateIndexRequest createIndexRequest = new CreateIndexRequest.Builder()
                    .index("autocomplete-index")
                    .withJson(new ByteArrayInputStream(json.getBytes(StandardCharsets.UTF_8)))
                    .build();

            CreateIndexResponse response = elasticsearchClient.indices().create(createIndexRequest);

            System.out.println("Index created: " + response.acknowledged());
        } catch (IOException e) {
            log.error("‚ùå Failed to create index", e);
            throw new RuntimeException("Failed to create index", e); // RuntimeException ÏúºÎ°ú Í∞êÏã∏ÏÑú ÏÉÅÏúÑÎ°ú ÎçòÏßê
        }
    }

    // Î¨∏ÏÑú Îì±Î°ù (Indexing) / ÏàòÏ†ï(delete + insert)
    public void indexDocument(String id, AutoComplete doc) {
        try {
            IndexResponse response = elasticsearchClient.index(i -> i
                    .index(INDEX_NAME)
                    .id(id)
                    .document(doc)
            );


        log.info("Document indexed with version: {}", response.version());
        } catch (IOException e) {
            log.error("‚ùå Failed to indexing", e);
            throw new RuntimeException(e);
        }
    }


    public List<AutoComplete> search(Map<String, String> param) {

        try {
            String _keyword = param.get("keyword");
            SearchResponse<AutoComplete> response = elasticsearchClient.search(s -> s
                                .index(INDEX_NAME)
                                .size(10)
                                .query(q -> q
                                        .bool(b -> b
                                                // üî∂ filter ‚Üí Î∞òÎìúÏãú ÏùºÏπòÌï¥Ïïº ÌïòÎäî ÌïÑÌÑ∞ Ï°∞Í±¥ (score Ïóê ÏòÅÌñ• X, Îπ†Î¶Ñ)
                                                .filter(f -> f.term(t -> t.field("coCd").value(param.get("coCd"))))   // coCd Í∞Ä Ï†ïÌôïÌûà param.get("coCd") ÏôÄ ÏùºÏπò
                                                .filter(f -> f.term(t -> t.field("divCd").value(param.get("divCd")))) // divCd Í∞Ä Ï†ïÌôïÌûà param.get("divCd") ÏôÄ ÏùºÏπò
                                                .filter(f -> f.term(t -> t.field("category").value(param.get("category")))) // category Í∞Ä Ï†ïÌôïÌûà param.get("category") ÏôÄ ÏùºÏπò

                                                // üî∂ should ‚Üí OR Ï°∞Í±¥, relevance score Ïóê ÏòÅÌñ• Ï§å (match ÎòêÎäî matchPhrasePrefix Î°ú ÏÇ¨Ïö©)
                                                .should(s1 -> s1.matchPhrasePrefix(mp -> mp
                                                        .field("code")           // code ÌïÑÎìúÏóêÏÑú
                                                        .query(_keyword)))       // _keywordÎ°ú ÏãúÏûëÌïòÎäî Î¨∏Ïû•(prefix) Îß§Ïπ≠

                                                .should(s2 -> s2.matchPhrasePrefix(mp -> mp
                                                        .field("name.ko")        // name.ko ÌïÑÎìúÏóêÏÑú
                                                        .query(_keyword)         // _keywordÎ°ú ÏãúÏûëÌïòÎäî Î¨∏Ïû•(prefix) Îß§Ïπ≠
                                                        .boost(2.0f)))           // Ïù¥ Ï°∞Í±¥Ïóê Í∞ÄÏ§ëÏπò(Ï§ëÏöîÎèÑ) 2Î∞∞ Î∂ÄÏó¨ ‚Üí Ïö∞ÏÑ†ÏàúÏúÑ ÎÜíÏùå

                                                .should(s3 -> s3.matchPhrasePrefix(mp -> mp
                                                        .field("name.en")        // name.en ÌïÑÎìúÏóêÏÑú
                                                        .query(_keyword)))       // _keywordÎ°ú ÏãúÏûëÌïòÎäî Î¨∏Ïû•(prefix) Îß§Ïπ≠
                                        )
                                ),
                        AutoComplete.class
                );

            return response.hits().hits().stream()
                    .map(hit -> {
                        AutoComplete doc = hit.source();
                        doc.setId(hit.id());  // _id Î≥ÑÎèÑ ÏÑ§Ï†ï (ÏõêÌïúÎã§Î©¥)
                        return doc;
                    })
                    .collect(Collectors.toList());
        } catch (IOException e) {
            log.error("‚ùå Failed to search", e);
            throw new RuntimeException(e);
        }

    };

    public void buildIndex(List<AutoComplete> docs) {
        int batchSize = 1000;
        int totalSize = docs.size();
        int totalBatches = (int) Math.ceil((double) totalSize / batchSize);
        long start = System.currentTimeMillis();

        log.info("üöÄ Ïù∏Îç±Ïã± ÏãúÏûë - Ï¥ù {}Í±¥, Î∞∞ÏπòÎãπ {}Í±¥ (Ï¥ù {}Î∞∞Ïπò)", totalSize, batchSize, totalBatches);

        for (int i = 0; i < totalSize; i += batchSize) {
            int currentBatch = (i / batchSize) + 1;

            List<BulkOperation> operations = docs.subList(i, Math.min(i + batchSize, totalSize))
                    .stream()
                    .map(doc -> BulkOperation.of(b -> b
                            .index(idx -> idx
                                    .index(INDEX_NAME)
                                    .id(doc.getId())
                                    .document(doc)
                            )
                    ))
                    .collect(Collectors.toList());

            BulkRequest bulkRequest = new BulkRequest.Builder()
                    .index(INDEX_NAME)
                    .operations(operations)
                    .build();

            BulkResponse bulkResponse = null;

            try {
                bulkResponse = elasticsearchClient.bulk(bulkRequest);
            } catch (IOException e) {
                log.error("‚ùå Failed to bulk", e);
                throw new RuntimeException(e);
            }

            log.info("‚úÖ [{} / {}] Î∞∞Ïπò ÏôÑÎ£å (ÏßÑÌñâÎ•†: {}%) - ÎàÑÏ†Å Ï≤òÎ¶¨ Î¨∏ÏÑú: {}Í±¥ (errors={})",
                    currentBatch,
                    totalBatches,
                    (currentBatch * 100) / totalBatches,
                    i + operations.size(),
                    bulkResponse.errors()
            );
        }

        long duration = System.currentTimeMillis() - start;
        log.info("üéâ Ïù∏Îç±Ïã± ÏôÑÎ£å! Ï¥ù ÏÜåÏöî ÏãúÍ∞Ñ: {}ms", duration);

//        üéâ Ïù∏Îç±Ïã± ÏôÑÎ£å! Ï¥ù ÏÜåÏöî ÏãúÍ∞Ñ: 27264ms
    }

    public void delete(String id){
        try {
            DeleteResponse response = elasticsearchClient.delete(d -> d
                    .index(INDEX_NAME)
                    .id(id)
            );

            log.info("Deleted document id={}, result={}", id, response.result().name());
        } catch (IOException e) {
            log.error("‚ùå Failed to delete", e);
            throw new RuntimeException(e);
        }
      }

}
